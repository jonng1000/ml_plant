Other comments - these refer to different ways of making ensemble models when there is no alpha
Precision and recall are best using majority vote (no usage of alpha). 
Tried scoring ensembles in different ways but it doesn't seem to change 
tpr and tnr that much. Threshold set to 4 (label a gene as SM when 4 models agree, no alpha used)
seems to produce slightly better results though.

Output when majority threshold = 3:
#print(classification_report(y_test, ensemble_predict))
#              precision    recall  f1-score   support
#
#           0       0.90      0.92      0.91       130
#           1       0.74      0.67      0.70        42
#
#    accuracy                           0.86       172
#   macro avg       0.82      0.79      0.80       172
#weighted avg       0.86      0.86      0.86       172

Output when majority threshold = 4:
#print(classification_report(y_test, l_ensemble_predict))
#              precision    recall  f1-score   support
#
#           0       0.91      0.83      0.87       130
#           1       0.58      0.74      0.65        42
#
#    accuracy                           0.81       172
#   macro avg       0.75      0.78      0.76       172

#weighted avg       0.83      0.81      0.82       172

Results in OneNote entry 8/11/19: basically ensemble performs in the range of individual models,
but is at the upper end. Varied alpha (threshold to convert average labels [in fractions] into
0s and 1s for individual models) and plotted graph to see how this affects ensemble scores 